{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adebfd6",
   "metadata": {},
   "source": [
    "# Big Data Project: Hipparcos Dataset Analysis with MongoDB and MapReduce\n",
    "\n",
    "This notebook demonstrates the Big Data project workflow:\n",
    "- Ingest the Hipparcos dataset into MongoDB.\n",
    "- Perform data preprocessing and cleaning.\n",
    "- Apply MapReduce for analysis.\n",
    "- Visualize insights.\n",
    "\n",
    "Dataset: Hipparcos catalog (118k+ stars) from Kaggle or similar source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e5673",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818caf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from bson.code import Code\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b251c5e",
   "metadata": {},
   "source": [
    "## 2. Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB running in Docker\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "\n",
    "# Create/select database and collection\n",
    "db = client[\"hipparcos_db\"]\n",
    "collection = db[\"stars\"]\n",
    "\n",
    "print(\"Connected to MongoDB\")\n",
    "print(\"Database:\", db.name)\n",
    "print(\"Collection:\", collection.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a09e43",
   "metadata": {},
   "source": [
    "## 3. Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94330a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Hipparcos dataset\n",
    "df = pd.read_csv(\"hipparcos-voidmain.csv\")\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492e7e9",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Fill missing spectral types with 'Unknown'\n",
    "df['SpType'] = df['SpType'].fillna('Unknown')\n",
    "\n",
    "# Fill missing parallaxes with 0 (for distant stars)\n",
    "df['Plx'] = df['Plx'].fillna(0)\n",
    "\n",
    "# Convert data types if needed (e.g., ensure numeric columns are float)\n",
    "numeric_cols = ['Vmag', 'Plx', 'pmRA', 'pmDE', 'RAdeg', 'DEdeg']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "print(\"Preprocessing complete. Missing values after cleaning:\")\n",
    "print(df.isnull().sum().sum(), \"total missing values\")\n",
    "\n",
    "# Prepare data for MongoDB (convert to list of dicts)\n",
    "data = df.to_dict('records')\n",
    "print(f\"Prepared {len(data)} documents for ingestion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac9422",
   "metadata": {},
   "source": [
    "## 5. Ingest Data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcace27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data into MongoDB\n",
    "try:\n",
    "    collection.insert_many(data)\n",
    "    print(\"Data ingestion successful!\")\n",
    "    print(f\"Inserted {len(data)} documents into {collection.name}\")\n",
    "except Exception as e:\n",
    "    print(\"Error during ingestion:\", e)\n",
    "\n",
    "# Verify insertion\n",
    "doc_count = collection.count_documents({})\n",
    "print(f\"Total documents in collection: {doc_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81f3b6",
   "metadata": {},
   "source": [
    "## 6. Apply MapReduce: Example 1 - Count Stars by Spectral Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MapReduce: Count stars by spectral type\n",
    "map_function = Code(\"\"\"\n",
    "function() {\n",
    "    emit(this.SpType, 1);\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "reduce_function = Code(\"\"\"\n",
    "function(key, values) {\n",
    "    return Array.sum(values);\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Run MapReduce\n",
    "result_collection = db[\"spectral_type_count\"]\n",
    "collection.map_reduce(map_function, reduce_function, out=result_collection.name)\n",
    "\n",
    "# Fetch and display results\n",
    "results = list(result_collection.find().sort(\"value\", -1).limit(10))\n",
    "print(\"Top 10 spectral types by count:\")\n",
    "for res in results:\n",
    "    print(f\"{res['_id']}: {res['value']} stars\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
